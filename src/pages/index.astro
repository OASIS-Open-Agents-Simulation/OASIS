---
import Header from '~/components/widgets/Header.astro';
import Hero2 from '~/components/widgets/Hero2.astro';
import Content from '~/components/widgets/Content.astro';

import { headerData } from '~/navigation';
import FAQs from '~/components/widgets/FAQs.astro';
import Brands from '~/components/widgets/Brands.astro';
import Timezone from '~/components/widgets/Timezone.astro';
import Layout from '~/layouts/PageLayout.astro';

const metadata = {
  title: 'Home',
};
---

<Layout metadata={metadata}>
  <Fragment slot="header">
    <Header {...headerData} isSticky />
  </Fragment>

  <!-- Hero2 Widget ******************* -->

  <Hero2
    tagline="ICML 2024 Workshop"
    actions={[
      { variant: 'primary', text: 'Get Started', href: '#features' },
      { text: 'Learn more', href: '#features' },
    ]}
  >
    <Fragment slot="title"> Multi-modal Foundation Model meets Embodied AI </Fragment>

    <Fragment slot="subtitle">
      The Forty-first International Conference on Machine Learning<span class="flex text-slate-500"
        >@ Messe Wien Exhibition Congress Center, Vienna
      </span><span class="text-slate-300 flex">Austria Sun Jul 21st —— Sat Jul 27th</span>
    </Fragment>
  </Hero2>

  <!-- Content Widget **************** -->

  <Content id="Overview">
    <Fragment slot="title"> Overview </Fragment><Fragment slot="subtitle"
      >Welcome to the ICML 2024 Workshop on Multi-modal Foundation Model meets Embodied AI(MFM-EAI)
    </Fragment>
    <Fragment slot="content"
      ><div class="mb-4">
        In recent years, Multi-modal Foundation Models (MFM) such as CLIP (17), ImageBind (11), DALL·E 3 (4), GPT 4V
        (15), and Gemini (19) have emerged as one of the most captivating and rapidly advancing areas in AI, drawing
        significant attention and progressing swiftly. The open-source community for MFM has also seen vigorous growth,
        with the emergence of models and algorithms like LLaVA (14), LAMM(22), Stable Diffusion (18), and OpenFlamingo
        (2). These MFMs are now actively exploring ultimate application scenarios beyond traditional computer vision
        tasks.
      </div>
      <div class="mb-4">
        Recent studies have unveiled the immense potential these models hold in empowering embodied AI agents, marking
        the intersection of these fields with a multitude of open questions and unexplored territories (7; 5; 6; 12).
        This workshop, MFM-EAI, is dedicated to exploring these critical challenges:

        <li class="ml-4">How can we train and evaluate MFM in open-ended environments?</li>
        <li class="ml-4">What constitutes an effective system architecture for MFM-based Embodied AI Agents?</li>
        <li class="ml-4">
          And importantly, how can MFM augment the perceptual and decision-making capabilities of these agents,
          balancing their high-level decision-making prowess with the nuanced requirements of low-level control in
          embodied systems?
        </li>
      </div>
      <div class="mb-4">
        This workshop aims to accelerate research and collaboration in computer vision and robotics. The event will
        advance multi-modal foundation models, enhancing the development of embodied AI systems capable of handling
        complex scenarios. Furthermore, it will focus on open-ended embodied agents, with potential applications in
        domestic service, healthcare, manufacturing, gaming, etc. Besides, the workshop will contribute to education and
        workforce development, fostering a skilled workforce and encouraging diversity in the field.
      </div>
    </Fragment>
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>

  <Content id="Call-For-Papers">
    <Fragment slot="title"> Call For Papers </Fragment>
    <Fragment slot="content"
      >Topics include but are not limited to:
      <li class="ml-4">Training and evaluation of MFM in open-ended scenar ios (14; 22)</li>
      <li class="ml-4">Data collection for training Embodied AI Agents and corre sponding MFM (6; 9; 10)</li>
      <li class="ml-4">Framework design for MFM-powered embodied agents (20; 16)</li>
      <li class="ml-4">Decision-making in Embodied Agents empowered by MFM(8; 1; 12)</li>
      <li class="ml-4">Low-level control in Embodied Agents empowered by MFM(13; 3)</li>
      <li class="ml-4">Evaluation and simulation of Embodied Agents (21)</li>
      <li class="ml-4">Limitations of MFM in empowering Embodied AI</li>
    </Fragment></Content
  >

  <!-- Content Widget **************** -->

  <Content id="Schedule">
    <Fragment slot="content">
      <h3 class="text-3xl font-bold tracking-tight dark:text-white sm:text-4xl mb-2 text-center">
        Schedule<br />
      </h3>
      <Timezone
        items={[
          {
            time: '2024-05-15T08:40:00',
            theme: {
              title: 'Opening Remarks (20 min)',
              subtitles: ['LoremLoremLoremLorem', 'LoremLoremLoremLorem'],
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '#',
          },
          {
            time: '2024-05-15T09:00:00',
            theme: {
              title: 'Invited talk 1(30 min)',
            },
            Speaker: 'Prof. Kristen Grauman',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T09:30:00',
            theme: {
              title: 'Invited talk 2(30 min)',
            },
            Speaker: ' Prof. Hao Su',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T10:00:00',
            theme: {
              title: 'Contributed Opinion Talk 1 (30 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T10:30:00',
            theme: {
              title: 'Coffee Break (15 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T10:45:00',
            theme: {
              title: 'Best Paper Talk #1 (15 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T11:00:00',
            theme: {
              title: 'Best Paper Talk #2 (15 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T11:15:00',
            theme: {
              title: 'Poster session & Lunch (120 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T13:15:00',
            theme: {
              title: 'Invited Talk #3(30 min)',
            },
            Speaker: 'Lerrel Pinto',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T13:45:00',
            theme: {
              title: 'Invited Talk #4(30 min)',
            },
            Speaker: 'Prof. Chuang Gan',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T14:15:00',
            theme: {
              title: 'Contributed Opinion Talk #2(30 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T14:45:00',
            theme: {
              title: 'Invited Talk #5(30 min)',
            },
            Speaker: 'Prof. Ziwei Liu',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T15:15:00',
            theme: {
              title: 'Coffee Break(15 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T15:30:00',
            theme: {
              title: 'Invited Talk #6(15 min)',
            },
            Speaker: 'Dr. Chris Paxton',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T16:00:00',
            theme: {
              title: 'Panel (60 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
          {
            time: '2024-05-15T17:00:00',
            theme: {
              title: 'Closing remarks (10 min)',
            },
            Speaker: '',
            institution: '',
            logoSrc: '/avatar.png',
            link: '',
          },
        ]}
      />
    </Fragment>
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>

  <!-- Brands Widget ****************** -->

  <Brands
    id="Speakers"
    title="Speakers"
    images={[
      {
        src: '/speaker01.png',
        alt: 'speaker01',
        name: 'Kristen Grauman',
        university: 'University of Texas at Austin',
        bioLink: 'https://www.cs.utexas.edu/users/grauman/',
      },
      {
        src: '/speaker02.png',
        alt: 'speaker02',
        name: 'Hao Su',
        university: 'UC San Diego',
        bioLink: 'https://cseweb.ucsd.edu/~haosu/',
      },
      {
        src: '/speaker03.png',
        alt: 'speaker03',
        name: 'Lerrel Pinto',
        university: 'NYU Courant',
        bioLink: 'https://www.lerrelpinto.com/',
      },
      {
        src: '/speaker04.png',
        alt: 'speaker04',
        name: 'Ishan Misra',
        university: 'FAIR',
        bioLink: 'https://imisra.github.io/',
      },
      {
        src: '/speaker05.png',
        alt: 'speaker05',
        name: 'Ziwei Liu',
        university: 'Nanyang Technological University',
        bioLink: 'https://liuziwei7.github.io/',
      },
      {
        src: '/speaker06.png',
        alt: 'speaker06',
        name: 'Chris Paxton',
        university: 'FAIR',
        bioLink: 'https://cpaxton.github.io/about/',
      },
      {
        src: '/speaker09.png',
        alt: 'speaker09',
        name: 'He Wang',
        university: 'Peking University',
        bioLink: 'https://hughw19.github.io/',
      },
      {
        src: '/speaker10.png',
        alt: 'speaker10',
        name: 'Joon Sung Park',
        university: 'Stanford University',
        bioLink: 'https://www.joonsungpark.com/',
      },
      {
        src: '/speaker11.png',
        alt: 'speaker11',
        name: 'Hao-Shu Fang',
        university: 'Stanford University',
        bioLink: 'https://fang-haoshu.github.io/',
      },
      {
        src: '/speaker12.png',
        alt: 'speaker12',
        name: 'Yilun Du',
        university: 'MIT EECS',
        bioLink: 'https://yilundu.github.io/',
      },
    ]}
  />
  <!-- Content Widget **************** -->

  <Content id="Challenges"
    ><Fragment slot="title"> Challenges</Fragment>
    <Fragment slot="content">
      <p class="mb-2">
        The EgoPlan Challenge aims to evaluate the potential of Multimodal Large Language Models (MLLMs) as embodied
        task planners in real-world scenarios. In this competition, models must predict the next feasible action using a
        real-time task progress video, current visual observation, and an open-form language instruction as inputs.
      </p><p class="mb-2">Questions are formulated as multiple-choice problems for objective evaluation.</p><p>
        Based on egocentric videos of everyday household activi ties, the EgoPlan Challenge features realistic tasks,
        diverse actions, and complex real-world visual observations. The competition consists of two phases:
      </p><li class="ml-2">
        In Phase 1, we will release human-verified validation and test datasets, along with a large-scale automatically
        constructed dataset, all sourced from Epic-Kitchens videos. Participants are encouraged to enhance model
        performance on the in domain test set by improving prompting strategies or lever aging large-scale data for
        instruction tuning.
      </li><li class="ml-2">
        In Phase 2, we will release an additional out-of-domain test set based on Ego4D videos, which has undergone
        strict hu man verification. This phase focuses on evaluating the do main generalization capabilities of MLLMs.
      </li>
    </Fragment><Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>
  <!-- Brands Widget ****************** -->

  <Brands
    id="Organizers"
    title="Organizers"
    icons={[]}
    images={[
      {
        src: '/organizer01.png',
        alt: 'organizer01',
        name: 'Zhenfei Yin',
        university: 'University of Sydney',
        bioLink: 'https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&hl=zh-CN',
      },
      {
        src: '/organizer12.png',
        alt: 'organizer12',
        name: 'Zhenhua Xu',
        university: 'The University of Hong Kong',
        bioLink: 'https://tonyxuqaq.github.io/',
      },
      {
        src: '/organizer05.png',
        alt: 'organizer05',
        name: 'Xihui Liu',
        university: 'The University of Hong Kong',
        bioLink: 'https://xh-liu.github.io/',
      },
      {
        src: '/organizer13.png',
        alt: 'organizer13',
        name: 'Mahi Shafiullah',
        university: 'New York University',
        bioLink: 'https://mahis.life/',
      },
      {
        src: '/organizer11.png',
        alt: 'organizer11',
        name: 'Quan Vuong',
        university: 'Google',
        bioLink: 'https://quanvuong.github.io/',
      },
      {
        src: '/organizer14.png',
        alt: 'organizer14',
        name: 'Yining Hong',
        university: 'University of California, Los Angeles',
        bioLink: 'https://evelinehong.github.io/',
      },
      {
        src: '/organizer08.png',
        alt: 'organizer08',
        name: 'Hengshuang Zhao',
        university: 'The University of Hong Kong',
        bioLink: 'https://hszhao.github.io/',
      },
      {
        src: '/organizer07.png',
        alt: 'organizer07',
        name: 'Mohamed Elhoseiny',
        university: 'King Abdullah University of Science and Technology',
        bioLink: 'https://www.mohamed-elhoseiny.com/',
      },
      {
        src: '/speaker08.png',
        alt: 'speaker08',
        name: 'Yang Jae Lee',
        university: 'Yale University',
        bioLink: 'https://medicine.yale.edu/profile/yangjae-lee/',
      },
      {
        src: '/organizer09.png',
        alt: 'organizer09',
        name: 'Takayuki Osa',
        university: 'The University of Tokyo',
        bioLink: 'https://takaosa.github.io/',
      },
      {
        src: '/organizer10.jpg',
        alt: 'organizer10',
        name: 'Lu Sheng',
        university: 'Beihang University',
        bioLink: 'https://scholar.google.com.hk/citations?user=_8lB7xcAAAAJ&hl=en',
      },
    ]}
  />

  <!-- Brands Widget ****************** -->

  <Brands
    id="Steering-Committee"
    title="Steering Committee"
    icons={[]}
    images={[
      {
        src: '/organizer06.png',
        alt: 'organizer06',
        name: 'Jing Shao',
        university: 'Shanghai AI Lab',
        bioLink: 'https://amandajshao.github.io/',
      },
      {
        src: '/committee04.png',
        alt: 'committee04',
        name: 'Yu Qiao',
        university: 'Shanghai AI Lab',
        bioLink: 'https://mmlab.siat.ac.cn/yuqiao',
      },
      {
        src: '/speaker07.png',
        alt: 'speaker07',
        name: 'Chuang Gan',
        university: 'MIT-IBM Watson AI Lab',
        bioLink: 'https://people.csail.mit.edu/ganchuang/',
      },
      {
        src: '/organizer03.png',
        alt: 'organizer03',
        name: 'Cewu Lu',
        university: 'Shanghai Jiao Tong University',
        bioLink: 'https://www.mvig.org/',
      },
      {
        src: '/organizer04.png',
        alt: 'organizer04',
        name: 'Tatsuya Harada',
        university: 'The University of Tokyo',
        bioLink: 'https://www.mi.t.u-tokyo.ac.jp/harada/',
      },
      {
        src: '/organizer02.png',
        alt: 'organizer02',
        name: 'Pete Florence',
        university: 'Google DeepMind',
        bioLink: 'https://www.peteflorence.com/',
      },
      {
        src: '/committee06.png',
        alt: 'committee06',
        name: 'Wanli Ouyang',
        university: 'Shanghai AI Lab',
        bioLink: 'https://wlouyang.github.io/',
      },

      {
        src: '/committee08.png',
        alt: 'committee08',
        name: 'Dacheng Tao',
        university: 'Nanyang Technological University',
        bioLink: 'https://ieeexplore.ieee.org/author/37269935500',
      },
      {
        src: '/committee09.png',
        alt: 'committee09',
        name: 'Philip Torr',
        university: 'University of Oxford',
        bioLink: 'https://www.robots.ox.ac.uk/~phst/',
      },
    ]}
    ><Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment></Brands
  >
  <Content id="References">
    <Fragment slot="title"> References </Fragment>
    <Fragment slot="content">
      <p>
        [1] L. Bailey, E. Ong, S. Russell, and S. Emmons. Image hijacks: Adversarial images can control generative
        models at runtime, 2023.
      </p>
      <p>
        [2] M. Bhatt, S. Chennabasappa, C. Nikolaidis, S. Wan, I. Evtimov, D. Gabi, D. Song, F. Ahmad, C. Aschermann, L.
        Fontana, S. Frolov, R. P. Giri, D. Kapil, Y. Kozyrakis, D. LeBlanc, J. Mi lazzo, A. Straumann, G. Synnaeve, V.
        Vontimitta, S. Whitman, and J. Saxe. Purple llama cyberseceval: A secure coding benchmark for language models,
        2023.
      </p>
    </Fragment>
  </Content>

  <!-- FAQs Widget ******************* -->

  <FAQs
    title="Frequently Asked Questions"
    items={[
      {
        title: 'Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus molestias laboriosam ',
        description: 'aliquam officiis nulla consectetur',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus molestias laboriosam ',
        description: 'aliquam officiis nulla consectetur',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus molestias laboriosam ',
        description: 'aliquam officiis nulla consectetur',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Lorem ipsum dolor sit amet consectetur adipisicing elit. Necessitatibus molestias laboriosam ',
        description: 'aliquam officiis nulla consectetur',
        icon: 'tabler:help-octagon',
      },
    ]}
  >
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </FAQs>
</Layout>
